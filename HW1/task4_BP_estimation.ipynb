{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Network for Regression (Estimate blood pressure from PPG signal)\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [HW page](http://kovan.ceng.metu.edu.tr/~sinan/DL/index.html) on the course website.*\n",
    "\n",
    "Having gained some experience with neural networks, let us train a network that estimates the blood pressure from a PPG signal window.\n",
    "\n",
    "All of your work for this exercise will be done in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Photoplethysmograph (PPG) signal\n",
    "\n",
    "A PPG (photoplethysmograph) signal is a signal obtained with a pulse oximeter, which illuminates the skin and measures changes in light absorption. A PPG signal carries rich information about the status of the cardiovascular health of a person, such as breadth rate, heart rate and blood pressure. An example is shown below, where you also see the blood pressure signal that we will estimate (the data also has the ECG signal, which you should ignore).\n",
    "\n",
    "<img width=\"80%\" src=\"PPG_ABG_ECG_example.png\">\n",
    "\n",
    "\n",
    "# Constructing the Dataset \n",
    "\n",
    "In this task, you are expected to perform the full pipeline for creating a learning system from scratch. Here is how you should construct the dataset:\n",
    "* Download the dataset from the following website, and only take \"Part 1\" from it (it is too big): https://archive.ics.uci.edu/ml/datasets/Cuff-Less+Blood+Pressure+Estimation\n",
    "* Take a window of size $W$ from the PPG channel between time $t$ and $t+W$. Let us call this $\\textbf{x}_t$.\n",
    "* Take the corresponding window of size $W$ from the ABP (arterial blood pressure) channel between time $t$ and $t+W$. Find the maxima and minima of this signal within the window (you can use \"findpeaks\" from Matlab or \"find_peaks_cwt\" from scipy). Here is an example window from the ABP signal, and its peaks:\n",
    " <img width=\"60%\" src=\"ABP_peaks.png\">\n",
    "    \n",
    "* Calculate the average of the maxima, call it $y^1_t$, and the average of the minima, call it $y^2_t$.\n",
    "* Slide the window over the PPG signals and collect many $(\\textbf{x}_t, <y^1_t, y^2_t>)$ instances. In other words, your network outputs two values.\n",
    "* This will be your input-output for training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from metu.data_utils import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import scipy.signal as signal\n",
    "#import analytic_wfm as AW\n",
    "#from peakdetect import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#store data in the array of 3 columns\n",
    "#1 - PPG 2 - APB 3 - ECG\n",
    "#with h5py.File('Part_2.mat', 'r') as f:\n",
    "#    Part = f['Part_2']\n",
    "#    dataset = np.array(f[Part[0].item()].value)\n",
    "#    f.close()\n",
    "#t = 0\n",
    "#W = 250\n",
    "#i = 0\n",
    "#X = np.zeros((size, W))\n",
    "#y = []\n",
    "#find peaks in array of APB in the array \n",
    "#of size W (sample slice (t, W+t) taken from dataset[:, 1])\n",
    "#while t<dataset.shape[0]:\n",
    "#    X[i, :] = np.array(dataset[t:W+t, 0]).reshape(W, 1).T\n",
    "#    abp = np.array(np.ravel(dataset[t:W+t, 1].reshape(W, 1).T))\n",
    "    #local maxima\n",
    "#    max_peaks = peakutils.indexes(abp, min_dist=50)\n",
    "    #local minima\n",
    "#    abp1 =1./abp\n",
    "#    min_peaks = peakutils.indexes(abp1, min_dist=50)\n",
    "    #means\n",
    "#    minp = np.mean([abp[k] for k in min_peaks])\n",
    "#    maxp = np.mean([abp[k] for k in max_peaks])\n",
    "    \n",
    "#    y.append((maxp, minp))\n",
    "#    t+=W\n",
    "#    i+=1\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "from cs231n.classifiers.neural_net_for_regression import TwoLayerNet\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "  np.random.seed(0)\n",
    "  return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "  np.random.seed(1)\n",
    "  X = 10 * np.random.randn(num_inputs, input_size)\n",
    "  y = np.array([[0, 1, 2], [1, 2, 3], [2, 3, 4], [2, 1, 4], [2, 1, 4]])\n",
    "  return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute scores\n",
    "Open the file `cs231n/classifiers/neural_net_for_regression.py` and look at the method `TwoLayerNet.loss`. This function is very similar to the loss functions you have written for the previous exercises: It takes the data and weights and computes the *regression* scores, the squared error loss, and the gradients on the parameters. \n",
    "\n",
    "To be more specific, you will implement the following loss function:\n",
    "\n",
    "$$\\frac{1}{2}\\sum_i\\sum_{j} (o_{ij} - y_{ij})^2 + \\frac{1}{2}\\lambda\\sum_j w_j^2,$$\n",
    "\n",
    "where $i$ runs through the samples in the batch; $o_{ij}$ is the prediction of the network for the $i^{th}$ sample for output $j$, and $y_{ij}$ is the correct value; $\\lambda$ is the weight of the regularization term.\n",
    "\n",
    "The first layer uses ReLU as the activation function. The output layer does not use any activation functions.\n",
    "\n",
    "Implement the first part of the forward pass which uses the weights and biases to compute the scores for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3]\n",
      " [6 5]]\n",
      "Your scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "correct scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Difference between your scores and correct scores:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 0], [1, 1]])\n",
    "b = np.array([[4, 3], [2, 2]])\n",
    "print(a.dot(b))\n",
    "scores = net.loss(X)\n",
    "print('Your scores:')\n",
    "print(scores)\n",
    "print()\n",
    "print('correct scores:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "# The difference should be very small. We get < 1e-7\n",
    "print('Difference between your scores and correct scores:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute loss\n",
    "In the same function, implement the second part that computes the data and regularizaion loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.3406756781\n",
      "Difference between your loss and correct loss:\n",
      "1.28444526126e-08\n"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 66.3406756909\n",
    "print(loss)\n",
    "# should be very small, we get < 1e-10\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "Implement the rest of the function. This will compute the gradient of the loss with respect to the variables `W1`, `b1`, `W2`, and `b2`. Now that you (hopefully!) have a correctly implemented forward pass, you can debug your backward pass using a numeric gradient check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 9.783744e-04\n",
      "b1 max relative error: 2.866381e-03\n",
      "W2 max relative error: 5.192568e-04\n",
      "b2 max relative error: 1.443396e-06\n"
     ]
    }
   ],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "  f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "  param_grad_num = eval_numerical_gradient(f, net.params[param_name])\n",
    "  #print(param_name, net.params[param_name])\n",
    "  print('{:s} max relative error: {:e}'.format(param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the PPG dataset for training your regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "Number of instances in the training set:  47\n",
      "Number of instances in the validation set:  2\n",
      "Number of instances in the testing set:  5\n"
     ]
    }
   ],
   "source": [
    "# Load the PPG dataset\n",
    "# If your memory turns out to be sufficient, try loading a subset\n",
    "def get_data(datafile, input_size, min_dist, training_ratio=0.85, test_ratio=0.1, val_ratio=0.05):\n",
    "  # Load the PPG training data \n",
    "  X, y = load_dataset(datafile, input_size, min_dist)\n",
    "    \n",
    "  # TODO: Split the data into training, validation and test sets\n",
    "  length=y.shape[0]\n",
    "  print(length)\n",
    "  num_training=int(length*training_ratio)\n",
    "  num_val = int(length*val_ratio)\n",
    "  num_test = min((length-num_training-num_val), int(length*test_ratio))\n",
    "  mask = range(num_training-1)\n",
    "  X_train = X[mask]\n",
    "  y_train = y[mask]\n",
    "  mask = range(num_training, num_training+num_test)\n",
    "  X_test = X[mask]\n",
    "  y_test = y[mask]\n",
    "  mask = range(num_training+num_test, num_training+num_test+num_val)\n",
    "  X_val = X[mask]\n",
    "  y_val = y[mask]\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "datafile = 'Part_2.mat' #TODO: PATH to your data file\n",
    "input_size = 1000 # TODO: Size of the input of the network\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data(datafile, 1000, 50)\n",
    "print(\"Number of instances in the training set: \", len(X_train))\n",
    "print(\"Number of instances in the validation set: \", len(X_val))\n",
    "print(\"Number of instances in the testing set: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now train our network on the PPG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 5000: loss 7541.986117\n",
      "iteration 100 / 5000: loss 7531.761004\n",
      "iteration 200 / 5000: loss 7523.720613\n",
      "iteration 300 / 5000: loss 7514.756031\n",
      "iteration 400 / 5000: loss 1.031111\n",
      "iteration 500 / 5000: loss 7439.633071\n",
      "iteration 600 / 5000: loss 7194.155516\n",
      "iteration 700 / 5000: loss 2.865658\n",
      "iteration 800 / 5000: loss 4.362320\n",
      "iteration 900 / 5000: loss 2230.913866\n",
      "iteration 1000 / 5000: loss 690.442074\n",
      "iteration 1100 / 5000: loss 181.734160\n",
      "iteration 1200 / 5000: loss 55.411435\n",
      "iteration 1300 / 5000: loss 22.264757\n",
      "iteration 1400 / 5000: loss 13.218272\n",
      "iteration 1500 / 5000: loss 10.200819\n",
      "iteration 1600 / 5000: loss 8.596948\n",
      "iteration 1700 / 5000: loss 8.226259\n",
      "iteration 1800 / 5000: loss 7.930614\n",
      "iteration 1900 / 5000: loss 7.643319\n",
      "iteration 2000 / 5000: loss 7.417014\n",
      "iteration 2100 / 5000: loss 7.223856\n",
      "iteration 2200 / 5000: loss 6.979904\n",
      "iteration 2300 / 5000: loss 6.916640\n",
      "iteration 2400 / 5000: loss 6.714074\n",
      "iteration 2500 / 5000: loss 6.688364\n",
      "iteration 2600 / 5000: loss 6.518439\n",
      "iteration 2700 / 5000: loss 6.516719\n",
      "iteration 2800 / 5000: loss 6.446255\n",
      "iteration 2900 / 5000: loss 6.384862\n",
      "iteration 3000 / 5000: loss 6.257985\n",
      "iteration 3100 / 5000: loss 6.211622\n",
      "iteration 3200 / 5000: loss 6.170843\n",
      "iteration 3300 / 5000: loss 6.205064\n",
      "iteration 3400 / 5000: loss 6.103128\n",
      "iteration 3500 / 5000: loss 6.074982\n",
      "iteration 3600 / 5000: loss 6.050029\n",
      "iteration 3700 / 5000: loss 6.027891\n",
      "iteration 3800 / 5000: loss 6.008220\n",
      "iteration 3900 / 5000: loss 6.063112\n",
      "iteration 4000 / 5000: loss 5.994028\n",
      "iteration 4100 / 5000: loss 6.059641\n",
      "iteration 4200 / 5000: loss 5.990662\n",
      "iteration 4300 / 5000: loss 6.056834\n",
      "iteration 4400 / 5000: loss 6.055653\n",
      "iteration 4500 / 5000: loss 5.986796\n",
      "iteration 4600 / 5000: loss 6.053627\n",
      "iteration 4700 / 5000: loss 5.984860\n",
      "iteration 4800 / 5000: loss 5.984039\n",
      "iteration 4900 / 5000: loss 6.051319\n",
      "Validation error:  0.145343841853\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train a neural network\n",
    "\n",
    "input_size = input_size\n",
    "hidden_size = 500 # TODO: Choose a suitable hidden layer size\n",
    "num_classes = 2 # We have two outputs\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "# Train the network\n",
    "stats = net.train(X_train, y_train, X_val, y_val, learning_rate=1e-5, learning_rate_decay=0.95, reg=0.5, num_iters=5000, batch_size=32,verbose=True)\n",
    "\n",
    "# Predict on the validation set\n",
    "#val_err = ... # TODO: Perform prediction on the validation set\n",
    "\n",
    "val_err = np.sum(np.square(net.predict(X_val) - y_val), axis=1).mean()\n",
    "print('Validation error: ', val_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the training and improve learning\n",
    "You should be able to get a validation error of 5.\n",
    "\n",
    "So far so good. But, is it really good? Let us plot the validation and training errors to see how good the network did. Did it memorize or generalize? Discuss your observations and conclusions. If its performance is not looking good, propose and test measures. This is the part that will show me how well you have digested everything covered in the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAHwCAYAAAAfLOO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQWxP8Hy4u/xq2w9xQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c09399780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and train / validation errors\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "train = plt.plot(stats['train_err_history'], label='train')\n",
    "val = plt.plot(stats['val_err_history'], label='val')\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.title('Classification error history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning and Improving Your Network (Bonus)\n",
    "There are many aspects and hyper-parameters you can play with. Do play with them and find the best setting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "228\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.001775 val err: 0.000099\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.001803 val err: 0.000101\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.001819 val err: 0.000101\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.002587 val err: 0.000105\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.002634 val err: 0.000108\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.002663 val err: 0.000109\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.001963 val err: 0.000110\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.001964 val err: 0.000110\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.002030 val err: 0.000114\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.002058 val err: 0.000115\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.002071 val err: 0.000116\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.007448 val err: 0.000120\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.002869 val err: 0.000121\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.002869 val err: 0.000121\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.007479 val err: 0.000122\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.007493 val err: 0.000123\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.002219 val err: 0.000124\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.002933 val err: 0.000125\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.007592 val err: 0.000128\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.002989 val err: 0.000128\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.007651 val err: 0.000132\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.007679 val err: 0.000133\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.007716 val err: 0.000136\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.007785 val err: 0.000140\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.007821 val err: 0.000142\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.009549 val err: 0.000242\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.005278 val err: 0.000260\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.005304 val err: 0.000261\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.004616 val err: 0.000262\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.005323 val err: 0.000263\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.005585 val err: 0.000278\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.005634 val err: 0.000280\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.004967 val err: 0.000283\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.010255 val err: 0.000284\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.005018 val err: 0.000286\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.005794 val err: 0.000290\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.005795 val err: 0.000290\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.005107 val err: 0.000291\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.005813 val err: 0.000291\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.005202 val err: 0.000296\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.005906 val err: 0.000297\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.005214 val err: 0.000297\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.005221 val err: 0.000297\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.005933 val err: 0.000298\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.005261 val err: 0.000300\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.005414 val err: 0.000308\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.010729 val err: 0.000312\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.006280 val err: 0.000318\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.010989 val err: 0.000331\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.011037 val err: 0.000334\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.011166 val err: 0.000338\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.011177 val err: 0.000342\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.006022 val err: 0.000343\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.006769 val err: 0.000345\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.011304 val err: 0.000346\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.006788 val err: 0.000346\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.011344 val err: 0.000348\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.006154 val err: 0.000351\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.007389 val err: 0.000381\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.012008 val err: 0.000382\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.012115 val err: 0.000389\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.007615 val err: 0.000394\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.006912 val err: 0.000394\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.006925 val err: 0.000395\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.006976 val err: 0.000398\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.007246 val err: 0.000414\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.012601 val err: 0.000418\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.007430 val err: 0.000424\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.008263 val err: 0.000431\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.013123 val err: 0.000448\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.007996 val err: 0.000457\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.008801 val err: 0.000463\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.008384 val err: 0.000479\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.009149 val err: 0.000483\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.009190 val err: 0.000485\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.013759 val err: 0.000485\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.009693 val err: 0.000514\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.014268 val err: 0.000519\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.014518 val err: 0.000533\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.014659 val err: 0.000538\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.014708 val err: 0.000544\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.044992 val err: 0.002587\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.045087 val err: 0.002592\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.045157 val err: 0.002596\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.045159 val err: 0.002596\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.045184 val err: 0.002598\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.046330 val err: 0.002621\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.046334 val err: 0.002621\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.046626 val err: 0.002638\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.046713 val err: 0.002643\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.047263 val err: 0.002674\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.052195 val err: 0.002691\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.052428 val err: 0.002705\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.052503 val err: 0.002709\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.052740 val err: 0.002723\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.053109 val err: 0.002744\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.065182 val err: 0.003749\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.066252 val err: 0.003811\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.066304 val err: 0.003814\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.067177 val err: 0.003820\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.066426 val err: 0.003821\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.066786 val err: 0.003841\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.067683 val err: 0.003850\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.067976 val err: 0.003866\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.067984 val err: 0.003866\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.068086 val err: 0.003872\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.067712 val err: 0.003895\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.073185 val err: 0.003901\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.068438 val err: 0.003937\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.074025 val err: 0.003946\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.068658 val err: 0.003949\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.074468 val err: 0.003971\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.069092 val err: 0.003974\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.069891 val err: 0.003977\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.069992 val err: 0.003982\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.070007 val err: 0.003983\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.070113 val err: 0.003989\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.069519 val err: 0.003999\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.070299 val err: 0.004000\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.069602 val err: 0.004004\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.070365 val err: 0.004004\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.074974 val err: 0.004004\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.069676 val err: 0.004008\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.075132 val err: 0.004009\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.071063 val err: 0.004044\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.070329 val err: 0.004045\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.076062 val err: 0.004063\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.076132 val err: 0.004067\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.076224 val err: 0.004073\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.076443 val err: 0.004085\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.076524 val err: 0.004093\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.076762 val err: 0.004106\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.077643 val err: 0.004154\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.073854 val err: 0.004204\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.079508 val err: 0.004262\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.098388 val err: 0.005661\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.101588 val err: 0.005845\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.102922 val err: 0.005877\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.103108 val err: 0.005888\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.108489 val err: 0.005927\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.107919 val err: 0.006210\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.109591 val err: 0.006261\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.110467 val err: 0.006311\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.137193 val err: 0.007895\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.139230 val err: 0.007967\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.139292 val err: 0.007970\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.140532 val err: 0.008042\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.145856 val err: 0.008076\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.141898 val err: 0.008166\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.142230 val err: 0.008185\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.143197 val err: 0.008195\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.142509 val err: 0.008201\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.143916 val err: 0.008237\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.149627 val err: 0.008293\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.150279 val err: 0.008330\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.150464 val err: 0.008341\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.152020 val err: 0.008431\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.148018 val err: 0.008519\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.153819 val err: 0.008534\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.155851 val err: 0.008651\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.158431 val err: 0.008799\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.191716 val err: 0.011035\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.286156 val err: 0.015219\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.288107 val err: 0.015322\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.333276 val err: 0.017725\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.341137 val err: 0.018123\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.345208 val err: 0.018223\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.360995 val err: 0.019179\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.363789 val err: 0.019211\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.367208 val err: 0.019510\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.376159 val err: 0.020006\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.433850 val err: 0.023074\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.445679 val err: 0.023683\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.454325 val err: 0.024026\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.458297 val err: 0.024375\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.424885 val err: 0.024461\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.426251 val err: 0.024540\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.427707 val err: 0.024573\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.427412 val err: 0.024607\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.431296 val err: 0.024780\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.431360 val err: 0.024783\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.436844 val err: 0.024816\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.431587 val err: 0.024847\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.433487 val err: 0.024956\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.433822 val err: 0.024976\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.433906 val err: 0.024981\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.435202 val err: 0.025004\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.435871 val err: 0.025043\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.435976 val err: 0.025049\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.444560 val err: 0.025261\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.444640 val err: 0.025265\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.444716 val err: 0.025269\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.440563 val err: 0.025313\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.446591 val err: 0.025377\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.441224 val err: 0.025402\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.442425 val err: 0.025471\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.443686 val err: 0.025493\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.483324 val err: 0.025567\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.446639 val err: 0.025663\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.454293 val err: 0.025821\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.490108 val err: 0.026046\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.509277 val err: 0.026948\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.515047 val err: 0.027393\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.516042 val err: 0.027426\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.527810 val err: 0.028072\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.534545 val err: 0.028430\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.542600 val err: 0.028720\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.510297 val err: 0.029042\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.549538 val err: 0.029207\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.522507 val err: 0.029745\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.563046 val err: 0.029807\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.528984 val err: 0.030119\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.583582 val err: 0.030899\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.545717 val err: 0.031367\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.556219 val err: 0.031685\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.595902 val err: 0.031694\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.560569 val err: 0.031936\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.560961 val err: 0.031958\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.555659 val err: 0.031991\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.558880 val err: 0.032125\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.558913 val err: 0.032127\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.563943 val err: 0.032130\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.560369 val err: 0.032210\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.565363 val err: 0.032212\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.565842 val err: 0.032239\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.561131 val err: 0.032307\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.567142 val err: 0.032314\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.563691 val err: 0.032454\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.565249 val err: 0.032544\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.572905 val err: 0.032645\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.570288 val err: 0.032834\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.573382 val err: 0.033012\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.623887 val err: 0.033182\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.577649 val err: 0.033205\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.578189 val err: 0.033236\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.578589 val err: 0.033259\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.578114 val err: 0.033285\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.581480 val err: 0.033425\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.582234 val err: 0.033469\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.641641 val err: 0.033986\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.592357 val err: 0.034105\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.598731 val err: 0.034132\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.649343 val err: 0.034515\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.678602 val err: 0.036093\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.685395 val err: 0.036433\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.721344 val err: 0.038366\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.688780 val err: 0.039657\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.786539 val err: 0.045287\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.857442 val err: 0.045605\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.860846 val err: 0.045644\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.862258 val err: 0.045861\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.862816 val err: 0.045869\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.866943 val err: 0.045969\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.867332 val err: 0.046110\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.867744 val err: 0.046153\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.874095 val err: 0.046349\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.872861 val err: 0.046425\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.877119 val err: 0.046630\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.877612 val err: 0.046657\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.879421 val err: 0.046774\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.886397 val err: 0.047003\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.885284 val err: 0.047086\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.886987 val err: 0.047155\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.889981 val err: 0.047314\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.892931 val err: 0.047351\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.892257 val err: 0.047435\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.894890 val err: 0.047455\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.892544 val err: 0.047472\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.893765 val err: 0.047516\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.894603 val err: 0.047560\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.897890 val err: 0.047615\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.898367 val err: 0.047640\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.896703 val err: 0.047693\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.897653 val err: 0.047722\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.900456 val err: 0.047871\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.905849 val err: 0.048037\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.907477 val err: 0.048124\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.905721 val err: 0.048173\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.908007 val err: 0.048295\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.913855 val err: 0.048464\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.914908 val err: 0.048640\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.918250 val err: 0.048697\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.916052 val err: 0.048722\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.917140 val err: 0.048780\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.918582 val err: 0.048835\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.922206 val err: 0.048907\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.934774 val err: 0.049718\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.938021 val err: 0.049749\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.938549 val err: 0.049919\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.868839 val err: 0.049970\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.942039 val err: 0.050083\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.944073 val err: 0.050191\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.943955 val err: 0.050207\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.948752 val err: 0.050319\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.951628 val err: 0.050615\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.952104 val err: 0.050618\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.958392 val err: 0.050832\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.886330 val err: 0.051033\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.959643 val err: 0.051041\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.964870 val err: 0.051297\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.893229 val err: 0.051374\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.966610 val err: 0.051412\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.970223 val err: 0.051461\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.970476 val err: 0.051596\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.973670 val err: 0.051644\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.906558 val err: 0.051848\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.980036 val err: 0.052104\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.915477 val err: 0.052655\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.997065 val err: 0.052889\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.932328 val err: 0.053625\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 0.952790 val err: 0.054509\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 0.952225 val err: 0.054827\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.958088 val err: 0.055165\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.964467 val err: 0.055181\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 0.961172 val err: 0.055286\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 0.970720 val err: 0.055540\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 0.975083 val err: 0.056144\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 0.982544 val err: 0.056222\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 0.979151 val err: 0.056378\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 0.981049 val err: 0.056431\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 0.982301 val err: 0.056559\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.074421 val err: 0.057146\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.030193 val err: 0.058965\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.027659 val err: 0.059171\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.034225 val err: 0.059197\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.042305 val err: 0.059958\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.174653 val err: 0.062477\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.179628 val err: 0.062720\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.181095 val err: 0.062798\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.185099 val err: 0.062888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.106326 val err: 0.063344\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.102969 val err: 0.063450\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.108558 val err: 0.063830\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.203284 val err: 0.064000\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.205708 val err: 0.064107\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.215379 val err: 0.064498\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 2.500000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.121444 val err: 0.064514\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.216018 val err: 0.064678\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 1.216058 val err: 0.064680\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.226076 val err: 0.065068\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 1.229288 val err: 0.065361\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.232543 val err: 0.065412\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.237058 val err: 0.065652\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.236643 val err: 0.065752\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.239771 val err: 0.065796\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.244882 val err: 0.066191\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 1.247641 val err: 0.066215\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.280477 val err: 0.067961\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 1.280069 val err: 0.068085\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 2.500000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.207057 val err: 0.069143\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.303271 val err: 0.069296\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 1.318033 val err: 0.069959\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.327648 val err: 0.070615\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.331578 val err: 0.070802\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.343305 val err: 0.071448\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.352422 val err: 0.071787\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.363863 val err: 0.072541\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.404464 val err: 0.074701\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 1.411674 val err: 0.075062\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.502642 val err: 0.079923\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.639428 val err: 0.087051\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.785326 val err: 0.094959\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.785359 val err: 0.094961\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.792036 val err: 0.095316\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.797082 val err: 0.095584\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.799129 val err: 0.095693\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.802133 val err: 0.095853\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.812244 val err: 0.096242\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 1.812647 val err: 0.096264\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.810550 val err: 0.096277\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.814252 val err: 0.096474\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 1.814752 val err: 0.096501\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.818936 val err: 0.096723\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.823637 val err: 0.096848\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.831714 val err: 0.097403\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 1.837668 val err: 0.097743\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.855763 val err: 0.098682\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 1.857069 val err: 0.098751\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 1.862756 val err: 0.098929\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 1.860435 val err: 0.098954\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.867698 val err: 0.099317\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.872810 val err: 0.099464\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 1.873351 val err: 0.099618\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 1.876238 val err: 0.099646\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 1.886603 val err: 0.100197\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 1.886760 val err: 0.100206\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 1.894333 val err: 0.100757\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 1.910564 val err: 0.101472\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 1.944928 val err: 0.103299\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 2.013841 val err: 0.107090\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 2.024624 val err: 0.107687\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 2.035479 val err: 0.108265\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 2.042329 val err: 0.108629\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 2.054743 val err: 0.109289\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 2.063756 val err: 0.109618\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 2.070055 val err: 0.110080\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 2.072462 val err: 0.110232\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 2.073455 val err: 0.110261\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 2.079182 val err: 0.110565\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 2.090685 val err: 0.111201\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 2.092439 val err: 0.111270\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 2.101316 val err: 0.111616\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 2.099037 val err: 0.111621\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 2.101640 val err: 0.111634\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 2.100057 val err: 0.111676\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 2.105732 val err: 0.112002\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 2.111495 val err: 0.112158\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 2.121661 val err: 0.112699\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 2.119707 val err: 0.112745\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 2.135730 val err: 0.113597\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 2.149986 val err: 0.114205\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 2.154036 val err: 0.114420\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 2.187291 val err: 0.116189\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 2.189790 val err: 0.116449\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 2.235779 val err: 0.118768\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 2.238292 val err: 0.119028\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 2.602073 val err: 0.138249\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 2.633147 val err: 0.140055\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.228114 val err: 0.140351\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.255473 val err: 0.141481\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 2.686515 val err: 0.142868\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.326979 val err: 0.144640\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.336286 val err: 0.145054\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 2.758913 val err: 0.146591\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 2.762119 val err: 0.146890\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.415589 val err: 0.148493\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 2.804261 val err: 0.149131\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 2.825520 val err: 0.150133\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 2.829423 val err: 0.150470\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 2.831773 val err: 0.150620\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 2.846949 val err: 0.151273\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 2.848054 val err: 0.151332\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.502555 val err: 0.152224\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 3.514409 val err: 0.152789\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 3.514991 val err: 0.152814\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.515193 val err: 0.152833\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 2.880022 val err: 0.153161\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.525323 val err: 0.153264\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 3.540302 val err: 0.153865\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 3.539066 val err: 0.153870\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.541444 val err: 0.153914\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.540553 val err: 0.153935\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.540975 val err: 0.153953\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 3.541318 val err: 0.153959\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.542605 val err: 0.153965\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.552973 val err: 0.154466\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 3.565863 val err: 0.155036\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 2.921870 val err: 0.155412\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 2.924007 val err: 0.155526\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 2.927177 val err: 0.155694\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 2.937460 val err: 0.156087\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 2.938576 val err: 0.156301\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 3.595152 val err: 0.156309\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 2.939957 val err: 0.156349\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 3.607625 val err: 0.156792\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 2.956149 val err: 0.157210\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 3.618819 val err: 0.157338\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 2.966406 val err: 0.157781\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 2.971644 val err: 0.158034\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 3.636233 val err: 0.158095\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 3.655999 val err: 0.158895\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.004900 val err: 0.159828\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 3.682039 val err: 0.160077\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.021161 val err: 0.160539\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 3.027828 val err: 0.161048\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 3.713127 val err: 0.161379\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 3.714804 val err: 0.161502\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.037634 val err: 0.161570\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.719605 val err: 0.161711\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.042864 val err: 0.161822\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.741805 val err: 0.162625\n",
      "hs: 3.000000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 3.743604 val err: 0.162704\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.744510 val err: 0.162743\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.750898 val err: 0.163071\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 3.752493 val err: 0.163140\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 3.108148 val err: 0.165165\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.816409 val err: 0.165929\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.825504 val err: 0.166264\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.828128 val err: 0.166438\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.832941 val err: 0.166638\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 3.833353 val err: 0.166656\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 3.848657 val err: 0.167271\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.873025 val err: 0.168390\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.885438 val err: 0.168870\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 3.887984 val err: 0.169041\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 3.893413 val err: 0.169277\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 3.895706 val err: 0.169367\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 3.897497 val err: 0.169394\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 3.193321 val err: 0.169695\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 3.908156 val err: 0.169858\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 3.907342 val err: 0.169873\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 3.915577 val err: 0.170240\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 3.923798 val err: 0.170588\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 3.956529 val err: 0.172021\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 3.997919 val err: 0.173821\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 4.036787 val err: 0.175450\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 4.044367 val err: 0.175780\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 4.070631 val err: 0.176922\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 4.075390 val err: 0.177189\n",
      "hs: 6.500000e+02 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 4.075876 val err: 0.177200\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 4.090178 val err: 0.177832\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 4.121017 val err: 0.179173\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 4.171706 val err: 0.181367\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 4.196009 val err: 0.182373\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 4.230984 val err: 0.183893\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 4.251135 val err: 0.184820\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 4.260380 val err: 0.185232\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 4.298753 val err: 0.186900\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 4.299838 val err: 0.186938\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 4.305285 val err: 0.187124\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 4.319525 val err: 0.187794\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 4.324173 val err: 0.187945\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 4.325314 val err: 0.187994\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 4.326955 val err: 0.188117\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 4.328475 val err: 0.188183\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 4.329504 val err: 0.188228\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 4.398720 val err: 0.191247\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 4.405108 val err: 0.191515\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 4.414072 val err: 0.191914\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 4.426664 val err: 0.192401\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 4.443739 val err: 0.193143\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 4.448928 val err: 0.193369\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 4.471115 val err: 0.194333\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 4.485977 val err: 0.195040\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 4.512882 val err: 0.196200\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 4.860587 val err: 0.211328\n",
      "hs: 5.000000e+01 lr: 1.100000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 4.961666 val err: 0.215722\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 5.118180 val err: 0.222517\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 5.419542 val err: 0.235620\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 5.508077 val err: 0.239469\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 8.436761 val err: 0.366748\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7232.226817 val err: 2.912859\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7231.133868 val err: 3.005546\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7229.895883 val err: 3.116066\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7229.888052 val err: 3.116785\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7229.871813 val err: 3.118277\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7229.870083 val err: 3.118436\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7229.851338 val err: 3.120160\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7229.841093 val err: 3.121103\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7229.803843 val err: 3.124535\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7229.777829 val err: 3.126936\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7229.766965 val err: 3.127939\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7258.975856 val err: 3.128027\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7258.971265 val err: 3.128448\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7258.969505 val err: 3.128610\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7258.965106 val err: 3.129014\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7258.961098 val err: 3.129382\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7258.938089 val err: 3.131497\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7258.936937 val err: 3.131603\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7229.653758 val err: 3.138424\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7258.860686 val err: 3.138627\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7258.809065 val err: 3.143397\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7258.691762 val err: 3.154278\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7258.686281 val err: 3.154788\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7229.472611 val err: 3.155318\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7229.420767 val err: 3.160180\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7258.582507 val err: 3.164466\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7229.361984 val err: 3.165708\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7397.650155 val err: 3.184671\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7397.649469 val err: 3.184734\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7397.646916 val err: 3.184968\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7397.641092 val err: 3.185502\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7397.640537 val err: 3.185552\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7397.620711 val err: 3.187371\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7258.331256 val err: 3.188098\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7397.607596 val err: 3.188575\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7397.596939 val err: 3.189554\n",
      "hs: 6.500000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7397.581321 val err: 3.190989\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7258.274798 val err: 3.193448\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7258.253098 val err: 3.195507\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7229.034684 val err: 3.196769\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7258.159371 val err: 3.204429\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7397.395245 val err: 3.208170\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7397.386168 val err: 3.209012\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7397.297385 val err: 3.217264\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7397.257705 val err: 3.220964\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7257.978342 val err: 3.221776\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7257.963871 val err: 3.223170\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7228.722084 val err: 3.226901\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7228.720889 val err: 3.227017\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7257.919393 val err: 3.227458\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7228.644230 val err: 3.234478\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7228.589749 val err: 3.239797\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7257.762591 val err: 3.242651\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7228.554584 val err: 3.243238\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7397.007942 val err: 3.244406\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7257.734572 val err: 3.245379\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7396.983336 val err: 3.246730\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7228.487293 val err: 3.249840\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7396.949484 val err: 3.249932\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7257.655795 val err: 3.253067\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7396.913103 val err: 3.253379\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7257.593701 val err: 3.259148\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7257.522573 val err: 3.266137\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7396.778668 val err: 3.266168\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7396.739525 val err: 3.269907\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7228.264226 val err: 3.271885\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7257.448083 val err: 3.273483\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7396.694922 val err: 3.274176\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7257.367613 val err: 3.281450\n",
      "hs: 5.000000e+01 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7396.522219 val err: 3.290791\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7396.396478 val err: 3.302975\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7396.245551 val err: 3.317697\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7396.109286 val err: 3.331083\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7396.106875 val err: 3.331320\n",
      "hs: 3.000000e+02 lr: 1.400000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7395.915050 val err: 3.350318\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7135.461073 val err: 3.413736\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7282.934762 val err: 3.483206\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7369.798645 val err: 3.524423\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7369.796333 val err: 3.525909\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7369.789739 val err: 3.530170\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7135.295925 val err: 3.533714\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7135.295030 val err: 3.534460\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7135.290311 val err: 3.538411\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7135.288842 val err: 3.539649\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7135.288385 val err: 3.540035\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7135.288161 val err: 3.540223\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7135.286816 val err: 3.541362\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7135.286273 val err: 3.541822\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7135.283183 val err: 3.544452\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7135.264255 val err: 3.560939\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7135.261265 val err: 3.563606\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7135.256263 val err: 3.568110\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7282.768010 val err: 3.603851\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7282.762545 val err: 3.608390\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7282.760733 val err: 3.609906\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7282.760286 val err: 3.610281\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7282.760015 val err: 3.610509\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7282.759923 val err: 3.610585\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7282.759581 val err: 3.610873\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7282.757777 val err: 3.612391\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7282.755361 val err: 3.614433\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7282.754409 val err: 3.615240\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7282.752344 val err: 3.616996\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7282.751308 val err: 3.617880\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7282.744317 val err: 3.623894\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7282.736907 val err: 3.630364\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7369.630594 val err: 3.645844\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7369.622565 val err: 3.652514\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7369.620837 val err: 3.653963\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7369.620711 val err: 3.654069\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7369.620573 val err: 3.654185\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7369.620061 val err: 3.654616\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7369.618377 val err: 3.656034\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7369.614404 val err: 3.659402\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7369.612470 val err: 3.661050\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7369.605941 val err: 3.666664\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 5.000000e+02 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7369.603022 val err: 3.669198\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7223.393146 val err: 3.828995\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7223.323620 val err: 3.838258\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7223.321394 val err: 3.838555\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7223.303427 val err: 3.840956\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7223.294072 val err: 3.842208\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7223.287596 val err: 3.843075\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7223.271250 val err: 3.845265\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7223.252557 val err: 3.847773\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7252.399333 val err: 3.849906\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7252.396188 val err: 3.850325\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7223.224534 val err: 3.851539\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7223.222982 val err: 3.851748\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7223.217151 val err: 3.852533\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7252.352664 val err: 3.856137\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7252.308421 val err: 3.862064\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7223.129650 val err: 3.864348\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7252.276644 val err: 3.866332\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7223.107587 val err: 3.867339\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7252.248608 val err: 3.870106\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7252.233713 val err: 3.872114\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7252.222090 val err: 3.873682\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7252.203600 val err: 3.876180\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7252.202227 val err: 3.876366\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7252.197987 val err: 3.876939\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7252.160111 val err: 3.882069\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7222.965017 val err: 3.886784\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7252.085349 val err: 3.892236\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7252.083415 val err: 3.892500\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7391.144871 val err: 3.892941\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7222.916496 val err: 3.893449\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7391.128337 val err: 3.895111\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7252.055040 val err: 3.896374\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7252.051634 val err: 3.896839\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7391.067587 val err: 3.903106\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7391.049685 val err: 3.905468\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7391.010942 val err: 3.910590\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7222.751104 val err: 3.916352\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7390.941140 val err: 3.919854\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7390.934872 val err: 3.920688\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7390.929971 val err: 3.921341\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7390.903045 val err: 3.924929\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7390.842250 val err: 3.933056\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7390.816005 val err: 3.936576\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7251.680639 val err: 3.948266\n",
      "hs: 6.500000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7390.727869 val err: 3.948442\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7390.657054 val err: 3.958031\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7222.385644 val err: 3.967999\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7390.430941 val err: 3.988978\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7251.382607 val err: 3.990648\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7390.417996 val err: 3.990765\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7222.003571 val err: 4.023611\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7390.170462 val err: 4.025271\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7221.967009 val err: 4.029024\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7251.033294 val err: 4.041611\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7250.989782 val err: 4.048061\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7250.963807 val err: 4.051923\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7389.977067 val err: 4.052681\n",
      "hs: 5.000000e+01 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7389.965435 val err: 4.054343\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7221.766160 val err: 4.059053\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7221.688602 val err: 4.070785\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7221.644654 val err: 4.077468\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7221.566067 val err: 4.089480\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7250.713926 val err: 4.089500\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 1.000000e+02 train err: 7250.696033 val err: 4.092221\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7221.529083 val err: 4.095161\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7389.668023 val err: 4.097338\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 2.500000e+01 train err: 7221.484974 val err: 4.101960\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 2.500000e+01 train err: 7221.467872 val err: 4.104604\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7389.593148 val err: 4.108321\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 2.500000e+01 train err: 7221.416788 val err: 4.112523\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7389.562435 val err: 4.112846\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7250.555969 val err: 4.113666\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 1.000000e+02 train err: 7250.524300 val err: 4.118551\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7250.451633 val err: 4.129811\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7389.447133 val err: 4.129931\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 1.000000e+02 train err: 7250.421053 val err: 4.134571\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 5.000000e+01 mind: 5.000000e+01 train err: 7389.341676 val err: 4.145698\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7389.289860 val err: 4.153495\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 3.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7389.195208 val err: 4.167824\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-01 inz: 1.000000e+03 hidz: 3.000000e+02 mind: 5.000000e+01 train err: 7389.128900 val err: 4.177929\n",
      "hs: 3.000000e+02 lr: 1.800000e-03 reg: 8.000000e-02 inz: 1.000000e+03 hidz: 6.500000e+02 mind: 5.000000e+01 train err: 7388.931538 val err: 4.208345\n",
      "best validation accuracy achieved during cross-validation: 0.000099\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "best_net = None\n",
    "best_val = math.inf\n",
    "results = {}\n",
    "learning_rates = [1.1e-3,1.4e-3,1.8e-3]\n",
    "regularization_strengths = [8e-2,3e-1,8e-1]    \n",
    "input_size = [250, 500, 1000]\n",
    "hidden_size = [50, 300, 650]\n",
    "min_dist = [25, 50, 100]\n",
    "num_classes = 2    \n",
    "k=0\n",
    "while k<len(hidden_size):\n",
    "    i=0\n",
    "    while i< len(learning_rates):\n",
    "        j = 0\n",
    "        while j < len(regularization_strengths):\n",
    "            t = 0\n",
    "            while t < len(input_size):\n",
    "                m = 0\n",
    "                while m<len(hidden_size):\n",
    "                    z = 0\n",
    "                    while z<len(min_dist):\n",
    "                        X_train, y_train, X_val, y_val, X_test, y_test = get_data(datafile, input_size[t], min_dist[z])\n",
    "                        net = TwoLayerNet(input_size[t], hidden_size[k], num_classes)\n",
    "                        stats = net.train(X_train, y_train, X_val, y_val,\n",
    "                        num_iters=2000, batch_size=200,\n",
    "                        learning_rate=learning_rates[i], learning_rate_decay=0.95,\n",
    "                        reg=regularization_strengths[j])\n",
    "                        #np.array([1 if a[0] == b[0] and a[1]==b[1] else 0 for (a, b) in zip(net.predict(X_val), y_val)]).mean()\n",
    "                        val_err = net.loss(X_val, y_val)[0]\n",
    "                        train_err = net.loss(X_train, y_train)[0]                     \n",
    "                        if best_val > val_err:\n",
    "                            best_val = val_err\n",
    "                            best_net = net\n",
    "                        results[(hidden_size[k], learning_rates[i], regularization_strengths[j], input_size[t], hidden_size[m], min_dist[z])] = (train_err, val_err)\n",
    "                        z=z+1\n",
    "                    m+=1\n",
    "                t+=1\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "    k=k+1\n",
    "results = sorted(results.items(), key=lambda x:x[1][1], reverse=False)\n",
    "for tup in results:\n",
    "    print('hs: {:e} lr: {:e} reg: {:e} inz: {:e} hidz: {:e} mind: {:e} train err: {:f} val err: {:f}'.format(\n",
    "                tup[0][0], tup[0][1], tup[0][2], tup[0][3], tup[0][4], tup[0][5], tup[1][0], tup[1][1]))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: {:f}'.format(best_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameters are: \n",
      " learning rate - 0.001800, regularization strength - 0.080000,\n",
      " input size - 250, hidden-layer_size - 650, min dist - 25\n",
      "Best validation error achieved during cross-validation: 0.000099\n"
     ]
    }
   ],
   "source": [
    "learning_rate = results[0][0][1]\n",
    "reg_s = results[0][0][2]   \n",
    "input_size = results[0][0][3]\n",
    "hidden_size = results[0][0][0]\n",
    "min_dist = results[0][0][5]\n",
    "print('Best hyper parameters are: \\n learning rate - {:f}, regularization strength - {:f},\\n input size - {:d}, hidden-layer_size - {:d}, min dist - {:d}'.format(learning_rate, reg_s, input_size, hidden_size, min_dist))\n",
    "print('Best validation error achieved during cross-validation: {:f}'.format(results[0][1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "Test err:  1.28179875882\n"
     ]
    }
   ],
   "source": [
    "input_size = results[0][0][3]\n",
    "min_dist = results[0][0][5]\n",
    "reg_s = results[0][0][2]\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data(datafile, input_size, min_dist)\n",
    "y_pred = best_net.predict(X_test)\n",
    "loss = 0.5*np.sum((y_pred - y_test)**2) + 0.5*reg_s*np.sum(best_net.params['W2']**2)+0.5*reg_s*np.sum(best_net.params['W1']**2)\n",
    "print('Test err: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
